{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the modules for retrieving data from the Yelp API.\n",
    "import requests\n",
    "import json\n",
    "#Load the modules for data manipulation.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the function that will be used for retrieveing data from Yelp's Business Search API.\n",
    "#The API returns a maximum of 1000 shops, and most of the search results return that many.\n",
    "#However, two of the results return only 750 (where yelp_pages=15).\n",
    "\n",
    "#api_key is the alias for my personal Yelp API Key, which has been omitted here.\n",
    "headers = {'Authorization': 'Bearer %s' % api_key}\n",
    "url='https://api.yelp.com/v3/businesses/search' \n",
    "\n",
    "def coffee_shops(term, location, yelp_pages=20):\n",
    "    \"\"\"\n",
    "    Inputs: search term, geopgraphical location, number of pages of returned results (maximum 50 results per page) \n",
    "    Output: dataframe with maximum 1000 rows of Yelp data where each row corresponds to a coffee shop\n",
    "    Terms: 'coffee', 'cafe', 'espresso', 'latte', 'cappuccino', 'macchiato', 'americano', 'mocha', 'decaf'\n",
    "    Locations: 'NYC', 'Manhattan', 'Brooklyn', 'Bronx', 'Queens', Staten Island'\n",
    "    \"\"\"\n",
    "    shop_id = []\n",
    "    name = []\n",
    "    review_count = []\n",
    "    rating = []\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    price = []\n",
    "    \n",
    "    #The Yelp API allows a maximum retrieval of 50 rows per page.\n",
    "    #yelp_pages=20 to acquire 1000 coffee shops; yelp_pages=15 to acquire 750 coffee shops in the two special cases.\n",
    "    for i in range(yelp_pages):\n",
    "        params = {'term':term, 'location':location, 'limit':50, 'offset':50*i, 'radius':0}\n",
    "        reqs = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        requests_text = json.loads(reqs.text)\n",
    "        businesses = requests_text['businesses']\n",
    "\n",
    "        for i in range(50):     \n",
    "            shop_id.append(businesses[i]['id'])\n",
    "            name.append(businesses[i]['name'])\n",
    "            review_count.append(businesses[i]['review_count'])\n",
    "            rating.append(businesses[i]['rating'])\n",
    "            latitude.append(businesses[i]['coordinates']['latitude'])\n",
    "            longitude.append(businesses[i]['coordinates']['longitude'])\n",
    "                 \n",
    "            #To accomodate the fact that some businesses do not have a 'price' value recorded.\n",
    "            if 'price' in list(businesses[i].keys()):\n",
    "                price.append(businesses[i]['price'])\n",
    "            else:\n",
    "                price.append('None')\n",
    "    \n",
    "    output = pd.DataFrame(np.array([shop_id, name, review_count, rating, latitude, longitude, price]).T)\n",
    "    output.columns = ['shop_id', 'name', 'review_count', 'rating', 'latitude', 'longitude', 'price']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a function that retrieves data from the Yelp API and generates a dataframe for each (search term, location) pair.\n",
    "\n",
    "def term_location_dictionary(term_list, location_list):\n",
    "    \"\"\"\n",
    "    Inputs: a list of search terms, a list of geographical locations\n",
    "    Output: a dictionary where each key is of the form '[term]_[location]' and the value corresponding to a key is a dataframe\n",
    "    consisting of 750 or 1000 rows of coffee shops retrieved from the Yelp API using that term and location in the search.\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    for pair in itertools.product(term_list, location_list):\n",
    "        term = pair[0]\n",
    "        location = pair[1]\n",
    "        if location == 'Staten_Island' and (term == 'macchiato' or term == 'decaf'):\n",
    "            dictionary[term + '_' + location] = coffee_shops(term, location.replace('_', ' '), 15)   #replace method for replacing 'Staten_Island' with 'Staten Island'\n",
    "        else:\n",
    "            dictionary[term + '_' + location] = coffee_shops(term, location.replace('_', ' '))   #replace method for replacing 'Staten_Island' with 'Staten Island'\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating the preliminary dataframe for this project: 'shops'.\n",
    "\n",
    "#Search parameters for the Yelp API.\n",
    "terms = ['coffee', 'cafe', 'espresso', 'latte', 'cappuccino', 'macchiato', 'americano', 'mocha', 'decaf']\n",
    "locations = ['NYC', 'Manhattan', 'Brooklyn', 'Bronx', 'Queens', 'Staten_Island']\n",
    "\n",
    "#A dictionary where each key is of the form '[term]_[location]' and the corresponding value is a dataframe of Yelp data.\n",
    "term_location_dict = term_location_dictionary(terms, locations)\n",
    "\n",
    "#Creating a list of all '[term]_[location]' strings, which are the keys to term_location_dict.\n",
    "term_location_list = []\n",
    "for pair in itertools.product(terms, locations):\n",
    "    term_location = pair[0] + '_' + pair[1]\n",
    "    term_location_list.append(term_location)\n",
    "\n",
    "#Combining the dataframes in term_location_dict into a single dataframe called 'shops' (with duplicate rows removed).\n",
    "shops = term_location_dict['coffee_NYC']\n",
    "for term_location in term_location_list:\n",
    "    shop_ids = set(shops['shop_id'])\n",
    "    term_location_dataframe = term_location_dict[term_location]\n",
    "    for i in range(term_location_dataframe.shape[0]):\n",
    "        if term_location_dataframe.iloc[i]['shop_id'] not in shop_ids:\n",
    "            shops = shops.append(term_location_dataframe.iloc[i], ignore_index=True)\n",
    "            \n",
    "#The numeric variables in shops are all of type str. Here we will convert them to the appropriate types.\n",
    "shops['review_count'] = shops['review_count'].astype(int)\n",
    "shops['rating'] = shops['rating'].astype(float)\n",
    "shops['latitude'] = shops['latitude'].astype(float)\n",
    "shops['longitude'] = shops['longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save shops to a .csv file.\n",
    "shops.to_csv('shops.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
